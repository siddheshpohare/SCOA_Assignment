{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CK4tF4UO8zAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d230eb77-2d19-4381-8263-9dc932020242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN in X: False\n",
            "NaN in y: False\n",
            "Epoch 1/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.5219 - loss: 0.6923\n",
            "Epoch 2/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.5213 - loss: 0.6923\n",
            "Epoch 3/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.5214 - loss: 0.6923\n",
            "Epoch 4/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.5211 - loss: 0.6923\n",
            "Epoch 5/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.5211 - loss: 0.6923\n",
            "Epoch 6/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.5197 - loss: 0.6924\n",
            "Epoch 7/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.5201 - loss: 0.6924\n",
            "Epoch 8/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.5212 - loss: 0.6923\n",
            "Epoch 9/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.5200 - loss: 0.6924\n",
            "Epoch 10/10\n",
            "\u001b[1m15476/15476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.5207 - loss: 0.6923\n",
            "\u001b[1m3869/3869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
            "Accuracy: 0.52\n",
            "Confusion Matrix:\n",
            "[[    0 59056]\n",
            " [    0 64750]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Step 1: Load data\n",
        "df = pd.read_csv('/content/SCOA_A5.csv')\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.lower()\n",
        "\n",
        "# Drop rows with missing or invalid values\n",
        "df = df.dropna(subset=['open', 'high', 'low', 'close', 'volume'])\n",
        "\n",
        "# Convert numeric columns properly\n",
        "for col in ['open', 'high', 'low', 'close', 'volume']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop remaining NaNs after conversion\n",
        "df = df.dropna()\n",
        "\n",
        "# Step 2: Target creation\n",
        "df['target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)\n",
        "df = df[:-1]  # remove last row (target becomes NaN)\n",
        "\n",
        "# Step 3: Features & scaling\n",
        "features = df[['open', 'high', 'low', 'close', 'volume']]\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(features)\n",
        "y = df['target'].values\n",
        "\n",
        "# Sanity check: no NaNs or inf\n",
        "print(\"NaN in X:\", np.isnan(X).any())\n",
        "print(\"NaN in y:\", np.isnan(y).any())\n",
        "\n",
        "# Step 4: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Step 5: Build & train ANN\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=5, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 6: Evaluate\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    }
  ]
}